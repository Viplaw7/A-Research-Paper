{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Viplaw7/A-Research-Paper/blob/main/ICTP_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Matrix Multiplication using TensorFlow on the GPU"
      ],
      "metadata": {
        "id": "AK8QuoAw_Med"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Create input matrices\n",
        "x = tf.constant(np.arange(16).reshape([4, 4]), dtype=tf.float32)\n",
        "y = tf.constant(np.ones([4, 4]), dtype=tf.float32)\n",
        "\n",
        "# Perform matrix multiplication on GPU\n",
        "z = tf.linalg.matmul(x, y)\n",
        "\n",
        "# Convert result to NumPy array and print\n",
        "print(\"Result from TensorFlow matrix multiplication:\")\n",
        "print(z.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3T4bzsJ_QG7",
        "outputId": "761b5fd6-5c3d-4c96-8070-7efb36a9c820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result from TensorFlow matrix multiplication:\n",
            "[[ 6.  6.  6.  6.]\n",
            " [22. 22. 22. 22.]\n",
            " [38. 38. 38. 38.]\n",
            " [54. 54. 54. 54.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Create input matrices with different values\n",
        "x = tf.constant(np.arange(1, 17).reshape([4, 4]), dtype=tf.float32)  # Matrix with values from 1 to 16\n",
        "y = tf.constant(np.arange(17, 33).reshape([4, 4]), dtype=tf.float32) # Matrix with values from 17 to 32\n",
        "\n",
        "\n",
        "\n",
        "# Convert result to NumPy array and print\n",
        "print(\"Matrix x:\")\n",
        "print(x.numpy())\n",
        "\n",
        "print(\"\\nMatrix y:\")\n",
        "print(y.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98vNZvEzHjEB",
        "outputId": "a5db6784-d571-4b0b-b2ee-3a8c80307b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix x:\n",
            "[[ 1.  2.  3.  4.]\n",
            " [ 5.  6.  7.  8.]\n",
            " [ 9. 10. 11. 12.]\n",
            " [13. 14. 15. 16.]]\n",
            "\n",
            "Matrix y:\n",
            "[[17. 18. 19. 20.]\n",
            " [21. 22. 23. 24.]\n",
            " [25. 26. 27. 28.]\n",
            " [29. 30. 31. 32.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Create input matrices\n",
        "x = tf.constant(np.arange(9).reshape([3, 3]), dtype=tf.float32)\n",
        "y = tf.constant(np.ones([3, 3]), dtype=tf.float32)\n",
        "\n",
        "# Perform matrix multiplication on GPU\n",
        "z = tf.linalg.matmul(x, y)\n",
        "\n",
        "# Convert result to NumPy array and print\n",
        "print(\"Result from TensorFlow matrix multiplication:\")\n",
        "print(z.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ayLt1XY_dRH",
        "outputId": "64cf4b48-ec5e-4396-ba1a-0750426f332a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result from TensorFlow matrix multiplication:\n",
            "[[ 3.  3.  3.]\n",
            " [12. 12. 12.]\n",
            " [21. 21. 21.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Create input matrices\n",
        "x = tf.constant(np.arange(4).reshape([2, 2]), dtype=tf.float32)\n",
        "y = tf.constant(np.ones([2, 2]), dtype=tf.float32)\n",
        "\n",
        "# Perform matrix multiplication on GPU\n",
        "z = tf.linalg.matmul(x, y)\n",
        "\n",
        "# Convert result to NumPy array and print\n",
        "print(\"Result from TensorFlow matrix multiplication:\")\n",
        "print(z.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfCwVPUK_o0M",
        "outputId": "53524f1c-65dc-4a84-d897-5f12435d075b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result from TensorFlow matrix multiplication:\n",
            "[[1. 1.]\n",
            " [5. 5.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Create input matrices with different data types\n",
        "x = tf.constant(np.arange(16).reshape([4, 4]), dtype=tf.float16)  # Change dtype to float16\n",
        "y = tf.constant(np.ones([4, 4]), dtype=tf.float16)                # Change dtype to float16\n",
        "\n",
        "# Perform matrix multiplication on GPU\n",
        "with tf.device('/device:GPU:0'):\n",
        "    z = tf.matmul(x, y)\n",
        "\n",
        "# Convert result to NumPy array and print\n",
        "print(\"Result from TensorFlow matrix multiplication:\")\n",
        "print(z.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOJ8zb4WCspA",
        "outputId": "2ff666e1-0536-415a-9bd4-aa0c39619841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result from TensorFlow matrix multiplication:\n",
            "[[ 6.  6.  6.  6.]\n",
            " [22. 22. 22. 22.]\n",
            " [38. 38. 38. 38.]\n",
            " [54. 54. 54. 54.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# use the CuPy library"
      ],
      "metadata": {
        "id": "eW30N6k_AwTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cupy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKKxkRRiBKMx",
        "outputId": "8dd9c2c5-5e23-4a40-defa-5184f2a2bc3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cupy\n",
            "  Downloading cupy-13.1.0.tar.gz (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<1.29,>=1.22 in /usr/local/lib/python3.10/dist-packages (from cupy) (1.25.2)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy) (0.8.2)\n",
            "Building wheels for collected packages: cupy\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for cupy (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for cupy\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for cupy\n",
            "Failed to build cupy\n",
            "\u001b[31mERROR: Could not build wheels for cupy, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp\n",
        "import numpy as np\n",
        "\n",
        "# Create input matrices\n",
        "x = cp.arange(16).reshape([4, 4])\n",
        "y = cp.ones([4, 4])\n",
        "\n",
        "# Perform matrix multiplication on GPU\n",
        "z = cp.matmul(x, y)\n",
        "\n",
        "# Convert result to NumPy array and print\n",
        "print(\"Result from CuPy matrix multiplication:\")\n",
        "print(cp.asnumpy(z))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxXxuNkpBiSA",
        "outputId": "f82570d9-2db9-4f99-c922-36030251cd7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result from CuPy matrix multiplication:\n",
            "[[ 6.  6.  6.  6.]\n",
            " [22. 22. 22. 22.]\n",
            " [38. 38. 38. 38.]\n",
            " [54. 54. 54. 54.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp\n",
        "import numpy as np\n",
        "\n",
        "# Create input matrices with different values\n",
        "x_np = np.arange(1, 17).reshape([4, 4]).astype(np.float32)  # Matrix with values from 1 to 16\n",
        "y_np = np.arange(17, 33).reshape([4, 4]).astype(np.float32) # Matrix with values from 17 to 32\n",
        "\n",
        "x = cp.array(x_np)\n",
        "y = cp.array(y_np)\n",
        "\n",
        "# Print the matrices\n",
        "print(\"Matrix x:\")\n",
        "print(cp.asnumpy(x))\n",
        "\n",
        "print(\"\\nMatrix y:\")\n",
        "print(cp.asnumpy(y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHkSy8rrIqoS",
        "outputId": "94504f1f-2f5e-4909-fa38-6d8e48e48403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix x:\n",
            "[[ 1.  2.  3.  4.]\n",
            " [ 5.  6.  7.  8.]\n",
            " [ 9. 10. 11. 12.]\n",
            " [13. 14. 15. 16.]]\n",
            "\n",
            "Matrix y:\n",
            "[[17. 18. 19. 20.]\n",
            " [21. 22. 23. 24.]\n",
            " [25. 26. 27. 28.]\n",
            " [29. 30. 31. 32.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp\n",
        "import numpy as np\n",
        "\n",
        "# Create input matrices\n",
        "x = cp.arange(9).reshape([3, 3])\n",
        "y = cp.ones([3, 3])\n",
        "\n",
        "# Perform matrix multiplication on GPU\n",
        "z = cp.matmul(x, y)\n",
        "\n",
        "# Convert result to NumPy array and print\n",
        "print(\"Result from CuPy matrix multiplication:\")\n",
        "print(cp.asnumpy(z))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sT8egdCbCCxR",
        "outputId": "dda2dcaa-743e-492a-d32d-3559f598a69a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result from CuPy matrix multiplication:\n",
            "[[ 3.  3.  3.]\n",
            " [12. 12. 12.]\n",
            " [21. 21. 21.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#use NumPy"
      ],
      "metadata": {
        "id": "fhIUw5mnESyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create input matrices with float32 data type\n",
        "x = np.arange(16, dtype=np.float32).reshape([4, 4])  # Matrix with values from 0 to 15\n",
        "y = np.ones([4, 4], dtype=np.float32)               # Matrix of ones\n",
        "\n",
        "# Print the matrices\n",
        "print(\"Matrix x:\")\n",
        "print(x)\n",
        "\n",
        "print(\"\\nMatrix y:\")\n",
        "print(y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AuDqZ_YET7T",
        "outputId": "b4caf44d-dd3b-4780-9ea7-ffea6b059f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix x:\n",
            "[[ 0.  1.  2.  3.]\n",
            " [ 4.  5.  6.  7.]\n",
            " [ 8.  9. 10. 11.]\n",
            " [12. 13. 14. 15.]]\n",
            "\n",
            "Matrix y:\n",
            "[[1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create input matrices\n",
        "x = np.arange(16).reshape([4, 4])  # Example matrix with values from 0 to 15\n",
        "y = np.ones([4, 4])                 # Matrix of ones\n",
        "\n",
        "# Print the matrices\n",
        "print(\"Matrix x:\")\n",
        "print(x)\n",
        "\n",
        "print(\"\\nMatrix y:\")\n",
        "print(y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOpgmkB1Eakd",
        "outputId": "c99c745a-9e22-4485-d625-1f9ffb3c87c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix x:\n",
            "[[ 0  1  2  3]\n",
            " [ 4  5  6  7]\n",
            " [ 8  9 10 11]\n",
            " [12 13 14 15]]\n",
            "\n",
            "Matrix y:\n",
            "[[1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#represent matrices using Numba"
      ],
      "metadata": {
        "id": "Ln181mqKGFTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numba import njit\n",
        "\n",
        "# Define a Numba JIT-compiled function to create input matrices\n",
        "@njit\n",
        "def create_matrices():\n",
        "    x = np.arange(16, dtype=np.float32).reshape((4, 4))  # Matrix with values from 0 to 15\n",
        "    y = np.ones((4, 4), dtype=np.float32)               # Matrix of ones\n",
        "    return x, y\n",
        "\n",
        "# Create input matrices\n",
        "x, y = create_matrices()\n",
        "\n",
        "# Print the matrices\n",
        "print(\"Matrix x:\")\n",
        "print(x)\n",
        "\n",
        "print(\"\\nMatrix y:\")\n",
        "print(y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSV_wEMWGG37",
        "outputId": "45287d53-eaca-4555-ae6a-7e1c86a65243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix x:\n",
            "[[ 0.  1.  2.  3.]\n",
            " [ 4.  5.  6.  7.]\n",
            " [ 8.  9. 10. 11.]\n",
            " [12. 13. 14. 15.]]\n",
            "\n",
            "Matrix y:\n",
            "[[1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Matrix** **Representation**"
      ],
      "metadata": {
        "id": "BuFXepvQMDAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from numba import cuda\n",
        "import numpy as np\n",
        "\n",
        "@cuda.jit\n",
        "def matmul(x, y, out):\n",
        "    start_x, start_y = cuda.grid(2)\n",
        "    stride_x, stride_y = cuda.gridsize(2)\n",
        "    for i in range(start_x, x.shape[0], stride_x):\n",
        "        for j in range(start_y, y.shape[1], stride_y):\n",
        "            tmp = 0\n",
        "            for k in range(x.shape[1]):\n",
        "                tmp += x[i, k] * y[k, j]\n",
        "            out[i, j] = tmp\n",
        "\n",
        "x_h = np.arange(16).reshape([4, 4])\n",
        "  y_h = np.ones([4, 4])\n",
        "z_h = np.zeros([4, 4])\n",
        "\n",
        "# Moving numpy arrays to GPU\n",
        "x_d = cuda.to_device(x_h)\n",
        "y_d = cuda.to_device(y_h)\n",
        "z_d = cuda.to_device(z_h)\n",
        "\n",
        "# Defining the grid on the GPU, using 32 threads per block\n",
        "threadsperblock = (32, 32)\n",
        "blockspergrid_x = math.ceil(z_h.shape[0] / threadsperblock[0])\n",
        "blockspergrid_y = math.ceil(z_h.shape[1] / threadsperblock[1])\n",
        "blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
        "\n",
        "# Performing the matmul\n",
        "matmul[blockspergrid, threadsperblock](x_d, y_d, z_d)\n",
        "\n",
        "# Copying the output array back to the CPU\n",
        "z_h = z_d.copy_to_host()\n",
        "\n",
        "print(z_h)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d7Z8ZCgMKq1",
        "outputId": "9adcfc15-1515-4fc4-8a04-dbd3f73d3732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6.  6.  6.  6.]\n",
            " [22. 22. 22. 22.]\n",
            " [38. 38. 38. 38.]\n",
            " [54. 54. 54. 54.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from numba import cuda\n",
        "import numpy as np\n",
        "\n",
        "@cuda.jit\n",
        "def matmul(x, y, out):\n",
        "    start_x, start_y = cuda.grid(2)\n",
        "    stride_x, stride_y = cuda.gridsize(2)\n",
        "    for i in range(start_x, x.shape[0], stride_x):\n",
        "        for j in range(start_y, y.shape[1], stride_y):\n",
        "            tmp = 0\n",
        "            for k in range(x.shape[1]):\n",
        "                tmp += x[i, k] * y[k, j]\n",
        "            out[i, j] = tmp\n",
        "\n",
        "@cuda.jit\n",
        "def scale_matrix(matrix, scalar):\n",
        "    x, y = cuda.grid(2)\n",
        "    if x < matrix.shape[0] and y < matrix.shape[1]:\n",
        "        matrix[x, y] *= scalar\n",
        "\n",
        "x_h = np.arange(16).reshape([4, 4])\n",
        "y_h = np.ones([4, 4])\n",
        "z_h = np.zeros([4, 4])\n",
        "\n",
        "# Moving numpy arrays to GPU\n",
        "x_d = cuda.to_device(x_h)\n",
        "y_d = cuda.to_device(y_h)\n",
        "z_d = cuda.to_device(z_h)\n",
        "\n",
        "# Defining the grid on the GPU, using 32 threads per block\n",
        "threadsperblock = (32, 32)\n",
        "blockspergrid_x = math.ceil(z_h.shape[0] / threadsperblock[0])\n",
        "blockspergrid_y = math.ceil(z_h.shape[1] / threadsperblock[1])\n",
        "blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
        "\n",
        "# Performing the matmul\n",
        "matmul[blockspergrid, threadsperblock](x_d, y_d, z_d)\n",
        "\n",
        "# Scaling the resulting matrix\n",
        "scale_factor = 2\n",
        "scale_matrix[blockspergrid, threadsperblock](z_d, scale_factor)\n",
        "\n",
        "# Copying the output array back to the CPU\n",
        "z_h = z_d.copy_to_host()\n",
        "\n",
        "print(z_h)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWYh_H2pIFXE",
        "outputId": "74e64d80-80ae-4533-91f9-60eb09e06de0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 12.  12.  12.  12.]\n",
            " [ 44.  44.  44.  44.]\n",
            " [ 76.  76.  76.  76.]\n",
            " [108. 108. 108. 108.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from numba import cuda\n",
        "import numpy as np\n",
        "\n",
        "@cuda.jit\n",
        "def matmul(x, y, out):\n",
        "    start_x, start_y = cuda.grid(2)\n",
        "    stride_x, stride_y = cuda.gridsize(2)\n",
        "    for i in range(start_x, x.shape[0], stride_x):\n",
        "        for j in range(start_y, y.shape[1], stride_y):\n",
        "            tmp = 0\n",
        "            for k in range(x.shape[1]):\n",
        "                tmp += x[i, k] * y[k, j]\n",
        "            out[i, j] = tmp\n",
        "\n",
        "@cuda.jit\n",
        "def scale_matrix(matrix, scalar):\n",
        "    x, y = cuda.grid(2)\n",
        "    if x < matrix.shape[0] and y < matrix.shape[1]:\n",
        "        matrix[x, y] *= scalar\n",
        "\n",
        "x_h = np.arange(16).reshape([4, 4])\n",
        "y_h = np.ones([4, 4])\n",
        "z_h = np.zeros([4, 4])\n",
        "\n",
        "# Moving numpy arrays to GPU\n",
        "x_d = cuda.to_device(x_h)\n",
        "y_d = cuda.to_device(y_h)\n",
        "z_d = cuda.to_device(z_h)\n",
        "\n",
        "# Defining the grid on the GPU, using 32 threads per block\n",
        "threadsperblock = (32, 32)\n",
        "blockspergrid_x = math.ceil(z_h.shape[0] / threadsperblock[0])\n",
        "blockspergrid_y = math.ceil(z_h.shape[1] / threadsperblock[1])\n",
        "blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
        "\n",
        "# Performing the matmul\n",
        "matmul[blockspergrid, threadsperblock](x_d, y_d, z_d)\n",
        "\n",
        "# Scaling the resulting matrix\n",
        "scale_factor = 2.5\n",
        "scale_matrix[blockspergrid, threadsperblock](z_d, scale_factor)\n",
        "\n",
        "# Copying the output array back to the CPU\n",
        "z_h = z_d.copy_to_host()\n",
        "\n",
        "print(z_h)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LHl6BIDIW_m",
        "outputId": "2be5570d-4dbd-4e3b-942c-e8c601964c85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 15.  15.  15.  15.]\n",
            " [ 55.  55.  55.  55.]\n",
            " [ 95.  95.  95.  95.]\n",
            " [135. 135. 135. 135.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from numba import cuda\n",
        "import numpy as np\n",
        "\n",
        "@cuda.jit\n",
        "def matmul(x, y, out):\n",
        "    start_x, start_y = cuda.grid(2)\n",
        "    stride_x, stride_y = cuda.gridsize(2)\n",
        "    for i in range(start_x, x.shape[0], stride_x):\n",
        "        for j in range(start_y, y.shape[1], stride_y):\n",
        "            tmp = 0\n",
        "            for k in range(x.shape[1]):\n",
        "                tmp += x[i, k] * y[k, j]\n",
        "            out[i, j] = tmp\n",
        "\n",
        "@cuda.jit\n",
        "def scale_matrix(matrix, scalar):\n",
        "    x, y = cuda.grid(2)\n",
        "    if x < matrix.shape[0] and y < matrix.shape[1]:\n",
        "        matrix[x, y] *= scalar\n",
        "\n",
        "@cuda.jit\n",
        "def add_scalar(matrix, scalar):\n",
        "    x, y = cuda.grid(2)\n",
        "    if x < matrix.shape[0] and y < matrix.shape[1]:\n",
        "        matrix[x, y] += scalar\n",
        "\n",
        "x_h = np.arange(16).reshape([4, 4])\n",
        "y_h = np.ones([4, 4])\n",
        "z_h = np.zeros([4, 4])\n",
        "\n",
        "# Moving numpy arrays to GPU\n",
        "x_d = cuda.to_device(x_h)\n",
        "y_d = cuda.to_device(y_h)\n",
        "z_d = cuda.to_device(z_h)\n",
        "\n",
        "# Defining the grid on the GPU, using 32 threads per block\n",
        "threadsperblock = (32, 32)\n",
        "blockspergrid_x = math.ceil(z_h.shape[0] / threadsperblock[0])\n",
        "blockspergrid_y = math.ceil(z_h.shape[1] / threadsperblock[1])\n",
        "blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
        "\n",
        "# Performing the matmul\n",
        "matmul[blockspergrid, threadsperblock](x_d, y_d, z_d)\n",
        "\n",
        "# Scaling the resulting matrix\n",
        "scale_factor = 2\n",
        "scale_matrix[blockspergrid, threadsperblock](z_d, scale_factor)\n",
        "\n",
        "# Adding a scalar value to the resulting matrix\n",
        "scalar_value = 5\n",
        "add_scalar[blockspergrid, threadsperblock](z_d, scalar_value)\n",
        "\n",
        "# Copying the output array back to the CPU\n",
        "z_h = z_d.copy_to_host()\n",
        "\n",
        "print(z_h)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTL2k691Kiah",
        "outputId": "684756f8-eb08-436c-d469-42f3405d6e3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 17.  17.  17.  17.]\n",
            " [ 49.  49.  49.  49.]\n",
            " [ 81.  81.  81.  81.]\n",
            " [113. 113. 113. 113.]]\n"
          ]
        }
      ]
    }
  ]
}